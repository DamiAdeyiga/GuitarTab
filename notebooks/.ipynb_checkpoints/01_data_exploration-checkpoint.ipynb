{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "To9K1GNWrb9x"
   },
   "source": [
    "# Data Exploration for GuitarTab Project\n",
    "\n",
    "This notebook explores the Guitar Chords V2 and GuitarSet datasets to understand their structure, distribution, and characteristics.\n",
    "01_data_exploration is focused solely on exploration\n",
    "## Table of Contents\n",
    "1. [Import Libraries](#Import-Libraries)\n",
    "2. [Define Paths and Parameters](#Define-Paths-and-Parameters)\n",
    "3. [Load Sample Audio Files](#Load-Sample-Audio-Files)\n",
    "4. [Visualize Waveforms](#Visualize-Waveforms)\n",
    "5. [Compute and Visualize Spectrograms](#Compute-and-Visualize-Spectrograms)\n",
    "6. [Class Distribution](#Class-Distribution)\n",
    "7. [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "d7Qqjkw4rS6y"
   },
   "outputs": [],
   "source": [
    "# 1. Import Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from src.data_preprocessing import get_file_paths, encode_labels, create_tf_datasets\n",
    "from src.models import create_crnn_model\n",
    "from src.data_preprocessing import load_wav_16k_mono, standardize_audio_length, compute_mel_spectrogram\n",
    "import librosa\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8SxI2ECrpGX"
   },
   "source": [
    "## 2. Define Paths and Parameters\n",
    "\n",
    "Setting the paths to the datasets and defining any necessary parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths and parameters\n",
    "# To match the actual raw data path:\n",
    "\n",
    "RAW_IDMT_PATH = \"data/raw/IDMT-SMT-CHORDS/guitar\"\n",
    "PROCESSED_DIR = \"data/processed/IDMT_CHORDS\"\n",
    "TRAIN_DIR = os.path.join(PROCESSED_DIR, \"Training\")\n",
    "TEST_DIR = os.path.join(PROCESSED_DIR, \"Test\")\n",
    "TRAIN_TEST_RATIO = 0.8\n",
    "batch_size = 32\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav_16k_mono(file_path):\n",
    "    \"\"\"Load a WAV file, resample to 16kHz and convert to mono\"\"\"\n",
    "    wav, sr = librosa.load(file_path, sr=16000, mono=True)\n",
    "    return wav\n",
    "\n",
    "def standardize_audio_length(wav, target_length=16000):\n",
    "    \"\"\"Standardize audio length by padding or truncating\"\"\"\n",
    "    if len(wav) > target_length:\n",
    "        return wav[:target_length]\n",
    "    else:\n",
    "        return np.pad(wav, (0, max(0, target_length - len(wav))), 'constant')\n",
    "\n",
    "def compute_mel_spectrogram(wav, sr=16000, n_mels=128, n_fft=2048, hop_length=512):\n",
    "    \"\"\"Compute mel spectrogram from waveform\"\"\"\n",
    "    mel_spec = librosa.feature.melspectrogram(\n",
    "        y=wav, sr=sr, n_mels=n_mels, n_fft=n_fft, hop_length=hop_length\n",
    "    )\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    \n",
    "    # Resize to fixed dimensions (128, 128) if needed\n",
    "    if mel_spec_db.shape[1] != 128:\n",
    "        # Using simple padding/truncation for consistency\n",
    "        target_length = 128\n",
    "        if mel_spec_db.shape[1] > target_length:\n",
    "            mel_spec_db = mel_spec_db[:, :target_length]\n",
    "        else:\n",
    "            padding = np.zeros((mel_spec_db.shape[0], target_length - mel_spec_db.shape[1]))\n",
    "            mel_spec_db = np.hstack((mel_spec_db, padding))\n",
    "    \n",
    "    return mel_spec_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chords():\n",
    "    \"\"\"Auto-detect chord classes\"\"\"\n",
    "    chords = []\n",
    "    for d in os.listdir(TRAIN_DIR):\n",
    "        dir_path = os.path.join(TRAIN_DIR, d)\n",
    "        if os.path.isdir(dir_path) and len(os.listdir(dir_path)) > 0:\n",
    "            chords.append(d)\n",
    "    return sorted(chords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ixhZ3lMTrjR6"
   },
   "outputs": [],
   "source": [
    "def verify_paths():\n",
    "    \"\"\"Verify all required directories and files exist\"\"\"\n",
    "    # Check base directories\n",
    "    assert os.path.exists(PROCESSED_DIR), f\"Missing base directory: {PROCESSED_DIR}\"\n",
    "    assert os.path.exists(TRAIN_DIR), f\"Missing training directory: {TRAIN_DIR}\"\n",
    "    assert os.path.exists(TEST_DIR), f\"Missing test directory: {TEST_DIR}\"\n",
    "    \n",
    "    # Check chord subfolders - using auto-detected chords\n",
    "    detected_chords = get_chords()\n",
    "    for split in [TRAIN_DIR, TEST_DIR]:\n",
    "        for chord in detected_chords:\n",
    "            chord_dir = os.path.join(split, chord)\n",
    "            assert os.path.exists(chord_dir), f\"Missing chord directory: {chord_dir}\"\n",
    "            assert len(os.listdir(chord_dir)) > 0, f\"No files in {chord_dir}\"\n",
    "    \n",
    "    print(\"All paths validated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alt86H5Rr9XF"
   },
   "source": [
    "## 3. Load Sample Audio Files\n",
    "\n",
    "Load a few sample audio files from each dataset to inspect their content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "kzpEgFRerjcK"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'data/processed/IDMT_CHORDS\\\\Training'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load sample audio file\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m chords \u001b[38;5;241m=\u001b[39m get_chords()  \u001b[38;5;66;03m# This line was missing\u001b[39;00m\n\u001b[0;32m      3\u001b[0m sample_chord \u001b[38;5;241m=\u001b[39m chords[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Use first available chord\u001b[39;00m\n\u001b[0;32m      4\u001b[0m sample_files \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(TRAIN_DIR, sample_chord, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*.wav\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "Cell \u001b[1;32mIn[9], line 4\u001b[0m, in \u001b[0;36mget_chords\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Auto-detect chord classes\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m chords \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(TRAIN_DIR):\n\u001b[0;32m      5\u001b[0m     dir_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(TRAIN_DIR, d)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(dir_path) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(dir_path)) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'data/processed/IDMT_CHORDS\\\\Training'"
     ]
    }
   ],
   "source": [
    "# Load sample audio file\n",
    "\n",
    "#chords = get_chords()  \n",
    "#sample_chord = chords[0]  # Use first available chord\n",
    "#sample_files = glob.glob(os.path.join(TRAIN_DIR, sample_chord, '*.wav'))\n",
    "#if sample_files:\n",
    "#    sample_file = sample_files[0]\n",
    "#    wav = load_wav_16k_mono(sample_file)\n",
    "#    print(f\"Audio Loaded: {sample_file}, Duration: {len(wav)/16000:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YuwHPWCEsJis"
   },
   "source": [
    "## 4. Visualize Waveforms\n",
    "\n",
    "Plot the waveform of the sample audio to understand its amplitude variations over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "WhLl1nTXrjd8"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wav' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[0;32m      9\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m---> 11\u001b[0m plot_waveform(wav, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWaveform of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_chord\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Chord\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'wav' is not defined"
     ]
    }
   ],
   "source": [
    "# 4. Visualize Waveforms\n",
    "def plot_waveform(wav, sr=16000, title=\"Waveform\"):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(np.arange(len(wav))/sr, wav)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_waveform(wav, title=f\"Waveform of {sample_chord} Chord\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6SXWNRoasR9c"
   },
   "source": [
    "## 5. Compute and Visualize Spectrograms\n",
    "\n",
    "Convert the audio waveform into a spectrogram and visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wav' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Standardize and compute mel spectrogram\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m wav_standardized \u001b[38;5;241m=\u001b[39m standardize_audio_length(wav)\n\u001b[0;32m     14\u001b[0m mel_spec \u001b[38;5;241m=\u001b[39m compute_mel_spectrogram(wav_standardized)\n\u001b[0;32m     15\u001b[0m plot_spectrogram(mel_spec, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMel Spectrogram of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_chord\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Chord\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'wav' is not defined"
     ]
    }
   ],
   "source": [
    "# 5. Compute and Visualize Spectrograms\n",
    "def plot_spectrogram(spectrogram, title=\"Spectrogram\"):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(spectrogram, aspect='auto', origin='lower', cmap='viridis')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Time Frame\")\n",
    "    plt.ylabel(\"Frequency Bin\")\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Standardize and compute mel spectrogram\n",
    "wav_standardized = standardize_audio_length(wav)\n",
    "mel_spec = compute_mel_spectrogram(wav_standardized)\n",
    "plot_spectrogram(mel_spec, title=f\"Mel Spectrogram of {sample_chord} Chord\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pl8HgX3XsZ-p"
   },
   "source": [
    "## 6. Class Distribution\n",
    "\n",
    "Analyze the distribution of chords in the Guitar Chords V2 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IQlzTSzlrjoI"
   },
   "outputs": [],
   "source": [
    "def get_all_files(dataset_path, chords):\n",
    "    \"\"\"Get all audio files and their labels from dataset path\"\"\"\n",
    "    files = []\n",
    "    labels = []\n",
    "    for chord in chords:\n",
    "        chord_path = os.path.join(dataset_path, chord)\n",
    "        if os.path.exists(chord_path):\n",
    "            chord_files = glob.glob(os.path.join(chord_path, '*.wav'))\n",
    "            files += chord_files\n",
    "            labels += [chord] * len(chord_files)\n",
    "    return files, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'verify_paths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 61\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchord\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpercentage\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 61\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Verify paths\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 5\u001b[0m     verify_paths()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWARNING: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'verify_paths' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    # Verify paths\n",
    "    try:\n",
    "        verify_paths()\n",
    "    except AssertionError as e:\n",
    "        print(f\"WARNING: {e}\")\n",
    "        print(\"Some paths may not exist yet. Run data_preparation.py first.\")\n",
    "        return\n",
    "    \n",
    "    # Auto-detect chords\n",
    "    chords = get_chords()\n",
    "    print(f\"Detected chords: {chords}\")\n",
    "    \n",
    "    # Load sample audio file\n",
    "    sample_chord = chords[0] if chords else None  # Use first available chord\n",
    "    if sample_chord:\n",
    "        sample_files = glob.glob(os.path.join(TRAIN_DIR, sample_chord, '*.wav'))\n",
    "        if sample_files:\n",
    "            sample_file = sample_files[0]\n",
    "            wav = load_wav_16k_mono(sample_file)\n",
    "            print(f\"Audio Loaded: {sample_file}, Duration: {len(wav)/16000:.2f} seconds\")\n",
    "            \n",
    "            # Visualize waveform\n",
    "            plot_waveform(wav, title=f\"Waveform of {sample_chord} Chord\")\n",
    "            \n",
    "            # Standardize and compute mel spectrogram\n",
    "            wav_standardized = standardize_audio_length(wav)\n",
    "            mel_spec = compute_mel_spectrogram(wav_standardized)\n",
    "            plot_spectrogram(mel_spec, title=f\"Mel Spectrogram of {sample_chord} Chord\")\n",
    "    \n",
    "    # Analyze class distribution\n",
    "    train_files, train_labels = get_all_files(TRAIN_DIR, chords)\n",
    "    test_files, test_labels = get_all_files(TEST_DIR, chords)\n",
    "    \n",
    "    # Combine and create a DataFrame\n",
    "    all_labels = train_labels + test_labels\n",
    "    df = pd.DataFrame({'Chord': all_labels})\n",
    "    \n",
    "    # Plot distribution\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.countplot(data=df, x='Chord', order=chords)\n",
    "    plt.title('Chord Distribution in Dataset')\n",
    "    plt.xlabel('Chord')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary stats\n",
    "    print(f\"Total samples: {len(all_labels)}\")\n",
    "    print(f\"Training samples: {len(train_labels)}\")\n",
    "    print(f\"Testing samples: {len(test_labels)}\")\n",
    "    print(\"\\nChord distribution:\")\n",
    "    for chord in chords:\n",
    "        count = df['Chord'].value_counts().get(chord, 0)\n",
    "        percentage = 100 * count / len(df)\n",
    "        print(f\"  {chord}: {count} samples ({percentage:.1f}%)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xCfNVPOfrjrv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
