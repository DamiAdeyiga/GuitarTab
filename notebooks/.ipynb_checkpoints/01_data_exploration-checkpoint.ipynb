{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "To9K1GNWrb9x"
   },
   "source": [
    "# Data Exploration for GuitarTab Project\n",
    "\n",
    "This notebook explores the Guitar Chords V2 and GuitarSet datasets to understand their structure, distribution, and characteristics.\n",
    "01_data_exploration is focused solely on exploration\n",
    "## Table of Contents\n",
    "1. [Import Libraries](#Import-Libraries)\n",
    "2. [Define Paths and Parameters](#Define-Paths-and-Parameters)\n",
    "3. [Load Sample Audio Files](#Load-Sample-Audio-Files)\n",
    "4. [Visualize Waveforms](#Visualize-Waveforms)\n",
    "5. [Compute and Visualize Spectrograms](#Compute-and-Visualize-Spectrograms)\n",
    "6. [Class Distribution](#Class-Distribution)\n",
    "7. [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "d7Qqjkw4rS6y"
   },
   "outputs": [],
   "source": [
    "# 1. Import Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from src.data_preprocessing import get_file_paths, encode_labels, create_tf_datasets\n",
    "from src.models import create_crnn_model\n",
    "from src.data_preprocessing import load_wav_16k_mono\n",
    "import librosa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8SxI2ECrpGX"
   },
   "source": [
    "## 2. Define Paths and Parameters\n",
    "\n",
    "Setting the paths to the datasets and defining any necessary parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ixhZ3lMTrjR6"
   },
   "outputs": [],
   "source": [
    "# 2. Define Paths and Parameters\n",
    "DATA_DIR = r\"C:\\Users\\User\\Documents\\GitHub\\GuitarTab\\Guitar_Chords_V2\"\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'Training')\n",
    "TEST_DIR = os.path.join(DATA_DIR, 'Test')\n",
    "chords = ['Am', 'Bb', 'Bdim', 'C', 'Dm', 'Em', 'F', 'G']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All paths validated successfully!\n"
     ]
    }
   ],
   "source": [
    "def verify_paths():\n",
    "    required_chords = ['Am', 'Bb', 'Bdim', 'C', 'Dm', 'Em', 'F', 'G']\n",
    "    \n",
    "    # Check base directories\n",
    "    assert os.path.exists(DATA_DIR), f\"Missing base directory: {DATA_DIR}\"\n",
    "    assert os.path.exists(TRAIN_DIR), f\"Missing training directory: {TRAIN_DIR}\"\n",
    "    assert os.path.exists(TEST_DIR), f\"Missing test directory: {TEST_DIR}\"\n",
    "    \n",
    "    # Check chord subfolders\n",
    "    for split in [TRAIN_DIR, TEST_DIR]:\n",
    "        for chord in required_chords:\n",
    "            chord_dir = os.path.join(split, chord)\n",
    "            assert os.path.exists(chord_dir), f\"Missing chord directory: {chord_dir}\"\n",
    "            assert len(os.listdir(chord_dir)) > 0, f\"No files in {chord_dir}\"\n",
    "    \n",
    "    print(\"All paths validated successfully!\")\n",
    "\n",
    "verify_paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alt86H5Rr9XF"
   },
   "source": [
    "## 3. Load Sample Audio Files\n",
    "\n",
    "Load a few sample audio files from each dataset to inspect their content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "kzpEgFRerjcK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio Loaded: C:\\Users\\User\\Documents\\GitHub\\GuitarTab\\Guitar_Chords_V2\\Training\\Am\\Am_AcusticPlug26_1.wav, Duration: 4.16 seconds\n"
     ]
    }
   ],
   "source": [
    "# 3. Load Sample Audio Files\n",
    "sample_chord = 'Am'\n",
    "sample_file = os.path.join(TRAIN_DIR, sample_chord, f'{sample_chord}_AcusticPlug26_1.wav')  # Update filename as needed\n",
    "wav = load_wav_16k_mono(sample_file)\n",
    "print(f\"Audio Loaded: {sample_file}, Duration: {len(wav)/16000:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YuwHPWCEsJis"
   },
   "source": [
    "## 4. Visualize Waveforms\n",
    "\n",
    "Plot the waveform of the sample audio to understand its amplitude variations over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WhLl1nTXrjd8"
   },
   "outputs": [],
   "source": [
    "# 4. Visualize Waveforms\n",
    "def plot_waveform(wav, sr=16000, title=\"Waveform\"):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(np.arange(len(wav))/sr, wav)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_waveform(wav, title=f\"Waveform of {sample_chord} Chord\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6SXWNRoasR9c"
   },
   "source": [
    "## 5. Compute and Visualize Spectrograms\n",
    "\n",
    "Convert the audio waveform into a spectrogram and visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Compute and Visualize Spectrograms\n",
    "def plot_spectrogram(spectrogram, title=\"Spectrogram\"):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(spectrogram, aspect='auto', origin='lower', cmap='viridis')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Time Frame\")\n",
    "    plt.ylabel(\"Frequency Bin\")\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Standardize and compute mel spectrogram\n",
    "wav_standardized = standardize_audio_length(wav)\n",
    "mel_spec = compute_mel_spectrogram(wav_standardized)\n",
    "plot_spectrogram(mel_spec, title=f\"Mel Spectrogram of {sample_chord} Chord\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pl8HgX3XsZ-p"
   },
   "source": [
    "## 6. Class Distribution\n",
    "\n",
    "Analyze the distribution of chords in the Guitar Chords V2 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IQlzTSzlrjoI"
   },
   "outputs": [],
   "source": [
    "# 6. Class Distribution\n",
    "import glob\n",
    "def get_all_files(dataset_path, chords):\n",
    "    files = []\n",
    "    labels = []\n",
    "    for chord in chords:\n",
    "        chord_path = os.path.join(dataset_path, chord, '*.wav')\n",
    "        chord_files = glob.glob(chord_path)\n",
    "        files += chord_files\n",
    "        labels += [chord] * len(chord_files)\n",
    "    return files, labels\n",
    "\n",
    "# Get train and test files\n",
    "train_files, train_labels = get_all_files(TRAIN_DIR, chords)\n",
    "test_files, test_labels = get_all_files(TEST_DIR, chords)\n",
    "\n",
    "# Combine and create a DataFrame\n",
    "all_labels = train_labels + test_labels\n",
    "df = pd.DataFrame({'Chord': all_labels})\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.countplot(data=df, x='Chord', order=chords)\n",
    "plt.title('Chord Distribution in Guitar Chords V2 Dataset')\n",
    "plt.xlabel('Chord')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# 7. Conclusion\n",
    "print(f\"Total samples: {len(all_labels)}\")\n",
    "print(f\"Training samples: {len(train_labels)}\")\n",
    "print(f\"Testing samples: {len(test_labels)}\")\n",
    "print(\"\\nChord distribution:\")\n",
    "for chord in chords:\n",
    "    count = df['Chord'].value_counts()[chord]\n",
    "    percentage = 100 * count / len(df)\n",
    "    print(f\"  {chord}: {count} samples ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xCfNVPOfrjrv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
