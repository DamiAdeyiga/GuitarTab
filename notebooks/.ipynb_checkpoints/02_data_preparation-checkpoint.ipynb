{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-zSztmpMVts"
   },
   "source": [
    "# Data Preparation for GuitarTab Project\n",
    "\n",
    "This notebook prepares the Guitar Chords V2 dataset for training the Chord Prediction Model. It includes loading audio files, converting them into spectrograms, encoding labels, and creating TensorFlow datasets for efficient training.\n",
    "\n",
    "02_data_preparation.ipynb main focus is on creating datasets for training:\n",
    "\n",
    "## Table of Contents\n",
    "1. [Import Libraries](#Import-Libraries)\n",
    "2. [Define Paths and Parameters](#Define-Paths-and-Parameters)\n",
    "3. [Load and Encode Labels](#Load-and-Encode-Labels)\n",
    "4. [Create TensorFlow Datasets](#Create-TensorFlow-Datasets)\n",
    "5. [Visualize Sample Spectrograms](#Visualize-Sample-Spectrograms)\n",
    "6. [Conclusion and Next Steps](#Conclusion-and-Next-Steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-POBN5IrMHQm"
   },
   "outputs": [],
   "source": [
    "# 1. Import Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from src.data_preprocessing import (\n",
    "    get_file_paths, encode_labels, compute_mel_spectrogram, \n",
    "    create_tf_datasets, preprocess_function\n",
    ")\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BD3wT5ykMd6l"
   },
   "source": [
    "## 2. Define Paths and Parameters\n",
    "\n",
    "Set the paths to your datasets and define any necessary parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xnd7ql7sMfDf"
   },
   "outputs": [],
   "source": [
    "# 2. Define Paths and Parameters\n",
    "DATA_DIR = r\"C:\\Users\\User\\Documents\\GitHub\\GuitarTab\\Guitar_Chords_V2\"\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'Training')\n",
    "TEST_DIR = os.path.join(DATA_DIR, 'Test')\n",
    "chords = ['Am', 'Bb', 'Bdim', 'C', 'Dm', 'Em', 'F', 'G']\n",
    "batch_size = 16\n",
    "num_classes = len(chords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_paths():\n",
    "    required_chords = ['Am', 'Bb', 'Bdim', 'C', 'Dm', 'Em', 'F', 'G']\n",
    "    \n",
    "    # Check base directories\n",
    "    assert os.path.exists(DATA_DIR), f\"Missing base directory: {DATA_DIR}\"\n",
    "    assert os.path.exists(TRAIN_DIR), f\"Missing training directory: {TRAIN_DIR}\"\n",
    "    assert os.path.exists(TEST_DIR), f\"Missing test directory: {TEST_DIR}\"\n",
    "    \n",
    "    # Check chord subfolders\n",
    "    for split in [TRAIN_DIR, TEST_DIR]:\n",
    "        for chord in required_chords:\n",
    "            chord_dir = os.path.join(split, chord)\n",
    "            assert os.path.exists(chord_dir), f\"Missing chord directory: {chord_dir}\"\n",
    "            assert len(os.listdir(chord_dir)) > 0, f\"No files in {chord_dir}\"\n",
    "    \n",
    "    print(\"All paths validated successfully!\")\n",
    "\n",
    "verify_paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BN36ZMLtMmdl"
   },
   "source": [
    "## 3. Load and Encode Labels\n",
    "\n",
    "Retrieve file paths and encode labels numerically and categorically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WhTGB77FMnbO"
   },
   "outputs": [],
   "source": [
    "# 3. Load and Encode Labels\n",
    "train_files, train_labels = get_file_paths(TRAIN_DIR, chords)\n",
    "test_files, test_labels = get_file_paths(TEST_DIR, chords)\n",
    "print(f\"Number of training samples: {len(train_files)}\")\n",
    "print(f\"Number of testing samples: {len(test_files)}\")\n",
    "\n",
    "# Encode labels\n",
    "label_encoder, train_labels_cat = encode_labels(train_labels)\n",
    "_, test_labels_cat = encode_labels(test_labels)\n",
    "print(f\"Encoded labels: {label_encoder.classes_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KkxKIkesMxZ1"
   },
   "source": [
    "## 4. Create TensorFlow Datasets\n",
    "\n",
    "Convert file paths and labels into TensorFlow datasets for efficient loading and preprocessing during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_77Fn0E_MyE7"
   },
   "outputs": [],
   "source": [
    "# 4. Create TensorFlow Datasets\n",
    "train_dataset, validation_dataset = create_tf_datasets(\n",
    "    train_files, train_labels_cat, \n",
    "    test_files, test_labels_cat,\n",
    "    batch_size=batch_size, \n",
    "    num_classes=num_classes\n",
    ")\n",
    "\n",
    "print(\"Training Dataset:\")\n",
    "for spectrogram, label in train_dataset.take(1):\n",
    "    print(spectrogram.shape, label.shape)\n",
    "print(\"Validation Dataset:\")\n",
    "for spectrogram, label in validation_dataset.take(1):\n",
    "    print(spectrogram.shape, label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBcRgBfkM2lW"
   },
   "source": [
    "## 5. Visualize Sample Spectrograms\n",
    "\n",
    "Visualize spectrograms to ensure data preprocessing is correct and to gain insights into the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WygiuoHSM3LR"
   },
   "outputs": [],
   "source": [
    "# 5. Visualize Sample Spectrograms\n",
    "def visualize_samples(dataset, label_encoder, num_samples=5):\n",
    "    class_names = label_encoder.classes_\n",
    "    plt.figure(figsize=(15, num_samples * 3))\n",
    "    for i, (spectrogram, label) in enumerate(dataset.take(num_samples)):\n",
    "        spectrogram = spectrogram.numpy().squeeze()\n",
    "        label = label.numpy()\n",
    "        predicted_label = class_names[np.argmax(label)]\n",
    "        plt.subplot(num_samples, 1, i+1)\n",
    "        plt.imshow(spectrogram, aspect='auto', origin='lower', cmap='viridis')\n",
    "        plt.title(f\"Chord: {predicted_label}\")\n",
    "        plt.xlabel(\"Time Frame\")\n",
    "        plt.ylabel(\"Frequency Bin\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize 5 samples from training dataset\n",
    "visualize_samples(train_dataset, label_encoder, num_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset preparation complete. Ready for model training!\")\n",
    "print(f\"Training dataset: {len(train_files)} samples\")\n",
    "print(f\"Validation dataset: {len(test_files)} samples\")\n",
    "print(f\"Input shape: (128, 128, 1)\")\n",
    "print(f\"Output shape: {num_classes} classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZO4a2XeTM7yQ"
   },
   "source": [
    "## 6. Conclusion and Next Steps\n",
    "\n",
    "- **Data Prepared**: Audio files have been loaded, preprocessed, and converted into spectrograms suitable for model training.\n",
    "- **Datasets Created**: TensorFlow datasets for training and validation are ready.\n",
    "- **Visual Verification**: Sample spectrograms have been visualized to ensure preprocessing correctness.\n",
    "\n",
    "### **Next Steps**\n",
    "- On Day 3, proceed to **Developing the Chord Prediction Model** by defining and training a CNN using the prepared datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGGrkEBwMURd"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
