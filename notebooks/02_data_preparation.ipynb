{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation for GuitarTab Project\n",
        "\n",
        "This notebook prepares the Guitar Chords V2 dataset for training the Chord Prediction Model. It includes loading audio files, converting them into spectrograms, encoding labels, and creating TensorFlow datasets for efficient training.\n",
        "\n",
        "## Table of Contents\n",
        "1. [Import Libraries](#Import-Libraries)\n",
        "2. [Define Paths and Parameters](#Define-Paths-and-Parameters)\n",
        "3. [Load and Encode Labels](#Load-and-Encode-Labels)\n",
        "4. [Create TensorFlow Datasets](#Create-TensorFlow-Datasets)\n",
        "5. [Visualize Sample Spectrograms](#Visualize-Sample-Spectrograms)\n",
        "6. [Conclusion and Next Steps](#Conclusion-and-Next-Steps)"
      ],
      "metadata": {
        "id": "W-zSztmpMVts"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-POBN5IrMHQm"
      },
      "outputs": [],
      "source": [
        "# 1. Import Libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from src.data_preprocessing import load_wav_16k_mono, preprocess_audio, compute_spectrogram, plot_waveform, plot_spectrogram, get_file_paths, encode_labels, preprocess_dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Define Paths and Parameters\n",
        "\n",
        "Set the paths to your datasets and define any necessary parameters."
      ],
      "metadata": {
        "id": "BD3wT5ykMd6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Define Paths and Parameters\n",
        "# Update these paths based on your local setup\n",
        "DATA_DIR = '/content/drive/MyDrive/GuitarTab/data/raw/GuitarChordsV2/'\n",
        "TRAIN_DIR = os.path.join(DATA_DIR, 'Training')\n",
        "TEST_DIR = os.path.join(DATA_DIR, 'Test')\n",
        "\n",
        "# Example chords (modify based on your dataset)\n",
        "chords = ['Am', 'Bb', 'Bdim', 'C', 'Dm', 'Em', 'F', 'G']"
      ],
      "metadata": {
        "id": "xnd7ql7sMfDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Load and Encode Labels\n",
        "\n",
        "Retrieve file paths and encode labels numerically and categorically."
      ],
      "metadata": {
        "id": "BN36ZMLtMmdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Load and Encode Labels\n",
        "train_files, train_labels = get_file_paths(TRAIN_DIR, chords)\n",
        "test_files, test_labels = get_file_paths(TEST_DIR, chords)\n",
        "\n",
        "print(f\"Number of training samples: {len(train_files)}\")\n",
        "print(f\"Number of testing samples: {len(test_files)}\")\n",
        "\n",
        "# Encode labels\n",
        "label_encoder, train_labels_cat = encode_labels(train_labels)\n",
        "_, test_labels_cat = encode_labels(test_labels)  # Ensure same encoding\n",
        "\n",
        "print(f\"Encoded labels: {label_encoder.classes_}\")"
      ],
      "metadata": {
        "id": "WhTGB77FMnbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Create TensorFlow Datasets\n",
        "\n",
        "Convert file paths and labels into TensorFlow datasets for efficient loading and preprocessing during training."
      ],
      "metadata": {
        "id": "KkxKIkesMxZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Create TensorFlow Datasets\n",
        "batch_size = 16\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# Create training and validation datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_files, train_labels_cat))\n",
        "train_dataset = train_dataset.map(lambda x, y: preprocess_dataset([x.numpy()], [y.numpy()]),\n",
        "                                num_parallel_calls=AUTOTUNE)\n",
        "train_dataset = train_dataset.unbatch()\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1000).batch(batch_size).prefetch(AUTOTUNE)\n",
        "\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices((test_files, test_labels_cat))\n",
        "validation_dataset = validation_dataset.map(lambda x, y: preprocess_dataset([x.numpy()], [y.numpy()]),\n",
        "                                          num_parallel_calls=AUTOTUNE)\n",
        "validation_dataset = validation_dataset.unbatch()\n",
        "validation_dataset = validation_dataset.batch(batch_size).prefetch(AUTOTUNE)\n",
        "\n",
        "print(\"Training Dataset:\")\n",
        "for spectrogram, label in train_dataset.take(1):\n",
        "    print(spectrogram.shape, label.shape)\n",
        "\n",
        "print(\"Validation Dataset:\")\n",
        "for spectrogram, label in validation_dataset.take(1):\n",
        "    print(spectrogram.shape, label.shape)"
      ],
      "metadata": {
        "id": "_77Fn0E_MyE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Visualize Sample Spectrograms\n",
        "\n",
        "Visualize spectrograms to ensure data preprocessing is correct and to gain insights into the input data."
      ],
      "metadata": {
        "id": "ZBcRgBfkM2lW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Visualize Sample Spectrograms\n",
        "import random\n",
        "\n",
        "def visualize_samples(dataset, label_encoder, num_samples=5):\n",
        "    class_names = label_encoder.classes_\n",
        "    plt.figure(figsize=(15, num_samples * 3))\n",
        "    for i, (spectrogram, label) in enumerate(dataset.take(num_samples)):\n",
        "        spectrogram = spectrogram.numpy().squeeze()\n",
        "        label = label.numpy()\n",
        "        predicted_label = class_names[np.argmax(label)]\n",
        "        plt.subplot(num_samples, 1, i+1)\n",
        "        plt.imshow(spectrogram, aspect='auto', origin='lower', cmap='viridis')\n",
        "        plt.title(f\"Chord: {predicted_label}\")\n",
        "        plt.xlabel(\"Time Frame\")\n",
        "        plt.ylabel(\"Frequency Bin\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize 5 samples from training dataset\n",
        "visualize_samples(train_dataset, label_encoder, num_samples=5)"
      ],
      "metadata": {
        "id": "WygiuoHSM3LR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Conclusion and Next Steps\n",
        "\n",
        "- **Data Prepared**: Audio files have been loaded, preprocessed, and converted into spectrograms suitable for model training.\n",
        "- **Datasets Created**: TensorFlow datasets for training and validation are ready.\n",
        "- **Visual Verification**: Sample spectrograms have been visualized to ensure preprocessing correctness.\n",
        "\n",
        "### **Next Steps**\n",
        "- On Day 3, proceed to **Developing the Chord Prediction Model** by defining and training a CNN using the prepared datasets."
      ],
      "metadata": {
        "id": "ZO4a2XeTM7yQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OGGrkEBwMURd"
      }
    }
  ]
}